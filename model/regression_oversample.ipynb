{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:16:00.116533Z",
     "iopub.status.busy": "2024-03-19T19:16:00.116131Z",
     "iopub.status.idle": "2024-03-19T19:16:00.123385Z",
     "shell.execute_reply": "2024-03-19T19:16:00.122137Z",
     "shell.execute_reply.started": "2024-03-19T19:16:00.116504Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['State', 'Sex', 'GeneralHealth', 'PhysicalHealthDays',\n",
      "       'MentalHealthDays', 'LastCheckupTime', 'PhysicalActivities',\n",
      "       'SleepHours', 'RemovedTeeth', 'HadHeartAttack', 'HadAngina',\n",
      "       'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD',\n",
      "       'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis',\n",
      "       'HadDiabetes', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty',\n",
      "       'DifficultyConcentrating', 'DifficultyWalking',\n",
      "       'DifficultyDressingBathing', 'DifficultyErrands', 'SmokerStatus',\n",
      "       'ECigaretteUsage', 'ChestScan', 'RaceEthnicityCategory', 'AgeCategory',\n",
      "       'HeightInMeters', 'WeightInKilograms', 'BMI', 'AlcoholDrinkers',\n",
      "       'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap',\n",
      "       'HighRiskLastYear', 'CovidPos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('../data/data2022.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:12:35.293478Z",
     "iopub.status.busy": "2024-03-19T19:12:35.292973Z",
     "iopub.status.idle": "2024-03-19T19:12:36.479651Z",
     "shell.execute_reply": "2024-03-19T19:12:36.478662Z",
     "shell.execute_reply.started": "2024-03-19T19:12:35.293434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncolumns_to_keep = [\\n    'HeartDisease','BMI', 'Smoking', 'Stroke', 'PhysicalHealthDays',\\n    'DiffWalking', 'Sex', 'AgeCategory', 'Diabetic',\\n    'Asthma', 'KidneyDisease'\\n]\\n\\ndf = df[columns_to_keep]\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/data2022.csv')\n",
    "df.head()\n",
    "'''\n",
    "columns_to_keep = [\n",
    "    'HeartDisease','BMI', 'Smoking', 'Stroke', 'PhysicalHealthDays',\n",
    "    'DiffWalking', 'Sex', 'AgeCategory', 'Diabetic',\n",
    "    'Asthma', 'KidneyDisease'\n",
    "]\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T19:12:52.897807Z",
     "iopub.status.busy": "2024-03-19T19:12:52.897437Z",
     "iopub.status.idle": "2024-03-19T19:12:54.24245Z",
     "shell.execute_reply": "2024-03-19T19:12:54.241085Z",
     "shell.execute_reply.started": "2024-03-19T19:12:52.897775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State\n",
      "Sex\n",
      "GeneralHealth\n",
      "LastCheckupTime\n",
      "PhysicalActivities\n",
      "RemovedTeeth\n",
      "HadHeartAttack\n",
      "HadAngina\n",
      "HadStroke\n",
      "HadAsthma\n",
      "HadSkinCancer\n",
      "HadCOPD\n",
      "HadDepressiveDisorder\n",
      "HadKidneyDisease\n",
      "HadArthritis\n",
      "HadDiabetes\n",
      "DeafOrHardOfHearing\n",
      "BlindOrVisionDifficulty\n",
      "DifficultyConcentrating\n",
      "DifficultyWalking\n",
      "DifficultyDressingBathing\n",
      "DifficultyErrands\n",
      "SmokerStatus\n",
      "ECigaretteUsage\n",
      "ChestScan\n",
      "RaceEthnicityCategory\n",
      "AgeCategory\n",
      "AlcoholDrinkers\n",
      "HIVTesting\n",
      "FluVaxLast12\n",
      "PneumoVaxEver\n",
      "TetanusLast10Tdap\n",
      "HighRiskLastYear\n",
      "CovidPos\n"
     ]
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "le=LabelEncoder()\n",
    "categorical = df.select_dtypes(include = 'O')\n",
    "categorical.columns\n",
    "for feature in categorical:\n",
    "    df1[feature]=le.fit_transform(df1[feature])\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, feature):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2,stratify=Y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2,stratify=df1[feature])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def over_sample_date(X_train, y_train, data_rate = 1):\n",
    "    minority_class = y_train.value_counts().idxmin()    # 1\n",
    "    majority_class = y_train.value_counts().idxmax()    # 0\n",
    "\n",
    "    minority_data = X_train[y_train == minority_class]\n",
    "    majority_data = X_train[y_train == majority_class]\n",
    "    minority_labels = y_train[y_train == minority_class]\n",
    "    majority_labels = y_train[y_train == majority_class]\n",
    "\n",
    "    oversampled_minority_data = minority_data.sample(int(len(majority_data)*data_rate), replace=True)\n",
    "    oversampled_minority_labels = minority_labels.sample(int(len(majority_data)*data_rate), replace=True)\n",
    "    X_train_oversampled = pd.concat([majority_data, oversampled_minority_data])\n",
    "    y_train_oversampled = pd.concat([majority_labels, oversampled_minority_labels])\n",
    "    return X_train_oversampled, y_train_oversampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change data_rate and other things to improve the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the training dataset and test dataset\n",
    "X=df1.drop('HadHeartAttack',axis=1)\n",
    "Y=df1['HadHeartAttack']\n",
    "X_train, X_test, y_train, y_test = split_data(X,Y, \"HadHeartAttack\")\n",
    "X_train_oversampled, Y_train_oversampled = over_sample_date(X_train, y_train, data_rate = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_oversampled_T = scaler.fit_transform(X_train_oversampled)\n",
    "X_test_T = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90     46518\n",
      "           1       0.21      0.77      0.33      2687\n",
      "\n",
      "    accuracy                           0.83     49205\n",
      "   macro avg       0.60      0.80      0.62     49205\n",
      "weighted avg       0.94      0.83      0.87     49205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[38747,  7771],\n",
       "       [  623,  2064]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_oversampled_T, Y_train_oversampled)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_T)\n",
    "#acc=log_reg.score(y_test,y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00136227,  0.37913133, -0.03444018,  0.0871154 ,  0.03910174,\n",
       "          0.11544806, -0.04395245, -0.05543116, -0.06759481,  1.17076279,\n",
       "          0.33339695,  0.03266067, -0.02204017,  0.06829962,  0.02989891,\n",
       "          0.06831557,  0.0286537 ,  0.18987811,  0.05294126,  0.06515129,\n",
       "          0.04416603,  0.09895978, -0.03410858,  0.0588833 , -0.21117684,\n",
       "          0.03572442,  0.34976337, -0.00572757,  0.69643557, -0.1476619 ,\n",
       "          0.17557901, -0.11312748, -0.13325854, -0.00568753, -0.0787146 ,\n",
       "          0.02571391, -0.01498358,  0.02436731,  0.02283218]]),\n",
       " array([0.16600727]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.coef_,log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00448853 -1.10945754 -0.16499011 -0.51520952 -0.18001931  0.37420921\n",
      "   0.64011494 -0.63060109 -0.48286087  1.65271139 -0.35163785  2.24666072\n",
      "   2.83439435  2.42463054 -0.53795208 -0.31438525  1.10011476  1.70584444\n",
      "  -0.40179989 -0.2973369  -0.39932005 -0.59019985 -0.2589463   2.83053256\n",
      "   0.77702643 -0.46208217  0.84454938 -0.29817373  0.3453844  -0.27890557\n",
      "   1.10014192  1.48333217 -0.95344425  1.43081769  0.85504849  0.95737533\n",
      "  -0.14575936 -0.18983213  1.61139995]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "def normalize_row(row, scaler):\n",
    "    # Reshape row to match expected input of scaler\n",
    "    row_reshaped = row.values.reshape(1, -1)\n",
    "    # Apply the same transformation as training data\n",
    "    normalized_row = scaler.transform(row_reshaped)\n",
    "    return normalized_row  # Flatten to match the shape of the original row\n",
    "\n",
    "# Fit scaler\n",
    "scaler = StandardScaler().fit(X_train_oversampled.values)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "df_new = X_train_oversampled.iloc[0]\n",
    "\n",
    "df_new_normalized = normalize_row(df_new, scaler)\n",
    "\n",
    "print(df_new_normalized)\n",
    "\n",
    "# If true, this proof the correctness of normalization\n",
    "print(X_train_oversampled_T[0] == df_new_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.63, 1.0, 0.0, 0.0, 0.0, 1.0, 10.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(list(X_train_oversampled.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability is: [0.16067047]\n"
     ]
    }
   ],
   "source": [
    "# Use user input to get \n",
    "import numpy as np\n",
    "\n",
    "user_input = [29.76, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0]\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler2 = pickle.load(f)\n",
    "user_input_T = normalize_row(pd.DataFrame([user_input]),scaler2)\n",
    "\n",
    "coef = np.array([0.09889642, 0.22637016, 0.30912101, 0.2488255 , 0.18334112,\n",
    "         0.37937364, 1.03940385, 0.25440507, 0.13933909, 0.17579232]).flatten()\n",
    "intercept = -1.29850855\n",
    "\n",
    "# Compute the linear combination of inputs and weights\n",
    "z = np.dot(user_input_T, coef) + intercept\n",
    "\n",
    "# Apply the logistic function\n",
    "p = 1 / (1 + np.exp(-z))\n",
    "\n",
    "print(\"The predicted probability is:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39\n",
      "GeneralHealth 0.36402090284437594\n",
      "PhysicalActivities 0.10137818621197459\n",
      "HadAngina 0.9737636569231289\n",
      "HadStroke 0.27964870799377695\n",
      "HadDiabetes 0.17573292365639212\n",
      "DifficultyWalking 0.08256261882192018\n",
      "SmokerStatus -0.19966559729113295\n",
      "ChestScan 0.3410593024476512\n",
      "AgeCategory 0.6594176125386868\n",
      "AlcoholDrinkers -0.12724874632043026\n",
      "FluVaxLast12 -0.08333360627771243\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "col = (list(df.columns[1:]))\n",
    "coef = (list(log_reg.coef_[0]))\n",
    "print(len(col), len(coef))\n",
    "num = 0;\n",
    "for i in range(len(col)):\n",
    "    if(coef[i] > 0.08 or coef[i] < -0.08):\n",
    "        print(col[i], coef[i])\n",
    "        num+=1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HadAngina\n",
      "AgeCategory\n",
      "GeneralHealth\n",
      "ChestScan\n",
      "HadStroke\n",
      "SmokerStatus\n",
      "HadDiabetes\n",
      "WeightInKilograms\n",
      "HeightInMeters\n",
      "AlcoholDrinkers\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns[1:])\n",
    "coefficients = list(log_reg.coef_[0])\n",
    "\n",
    "features_with_coef = list(zip(columns, coefficients))\n",
    "\n",
    "sorted_features = sorted(features_with_coef, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "top_features = sorted_features[:10]\n",
    "\n",
    "for feature, coef in top_features:\n",
    "    print(feature)\n",
    "print(len(top_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "    \"HadAngina\",\n",
    "    \"AgeCategory\",\n",
    "    \"GeneralHealth\",\n",
    "    \"ChestScan\",\n",
    "    \"HadStroke\",\n",
    "    \"SmokerStatus\",\n",
    "    \"HadDiabetes\",\n",
    "    \"WeightInKilograms\",\n",
    "    \"HeightInMeters\",\n",
    "    \"AlcoholDrinkers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90     46518\n",
      "           1       0.20      0.76      0.32      2687\n",
      "\n",
      "    accuracy                           0.83     49205\n",
      "   macro avg       0.59      0.80      0.61     49205\n",
      "weighted avg       0.94      0.83      0.87     49205\n",
      "\n",
      "[[ 1.20418188  0.71994361 -0.07368749  0.4308176   0.38058965 -0.29344281\n",
      "   0.23605199  0.13270312  0.09138451 -0.16525378]] [0.15924511]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./saved_files/logistic_model.joblib']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "df=pd.read_csv('../data/data2022.csv')\n",
    "df.head()\n",
    "\n",
    "feature_list = [\n",
    "    \"HadHeartAttack\",\n",
    "    \"HadAngina\",\n",
    "    \"AgeCategory\",\n",
    "    \"GeneralHealth\",\n",
    "    \"ChestScan\",\n",
    "    \"HadStroke\",\n",
    "    \"SmokerStatus\",\n",
    "    \"HadDiabetes\",\n",
    "    \"WeightInKilograms\",\n",
    "    \"HeightInMeters\",\n",
    "    \"AlcoholDrinkers\"\n",
    "]\n",
    "\n",
    "df = df[feature_list]\n",
    "df1 = df.copy()\n",
    "le=LabelEncoder()\n",
    "categorical = df.select_dtypes(include = 'O')\n",
    "categorical.columns\n",
    "for feature in categorical:\n",
    "    df1[feature]=le.fit_transform(df1[feature])\n",
    "\n",
    "X=df1.drop('HadHeartAttack',axis=1)\n",
    "Y=df1['HadHeartAttack']\n",
    "X_train, X_test, y_train, y_test = split_data(X,Y, \"HadHeartAttack\")\n",
    "X_train_oversampled, Y_train_oversampled = over_sample_date(X_train, y_train, data_rate = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train_oversampled_T = scaler.fit_transform(X_train_oversampled)\n",
    "X_test_T = scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_oversampled_T, Y_train_oversampled)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_T)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(log_reg.coef_,log_reg.intercept_)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_oversampled.values)\n",
    "with open('./saved_files/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "dump(log_reg, './saved_files/logistic_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.68924272 0.31075728]\n",
      " [0.50556966 0.49443034]\n",
      " [0.51268851 0.48731149]\n",
      " [0.62306698 0.37693302]\n",
      " [0.87725271 0.12274729]\n",
      " [0.67972368 0.32027632]\n",
      " [0.87716042 0.12283958]\n",
      " [0.74783605 0.25216395]\n",
      " [0.9073931  0.0926069 ]\n",
      " [0.9385693  0.0614307 ]\n",
      " [0.79489329 0.20510671]]\n"
     ]
    }
   ],
   "source": [
    "# Load the model back from the file\n",
    "\n",
    "loaded_model = load('./saved_files/logistic_model.joblib')\n",
    "\n",
    "# Use loaded_model to predict or evaluate to ensure it works\n",
    "predictions = loaded_model.predict_proba(X_test_T[20:31])\n",
    "print(predictions[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1936563,
     "sourceId": 6674905,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
